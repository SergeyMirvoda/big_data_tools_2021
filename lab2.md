# Лабораторная работа №1
> Цель работы: закомство с распределённой файловой системой HDFS.

## Задание 1
1. Воспользовавшись [справкой](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html), схемой кластера из презентации (Лабораторная №2) и [примером](https://medium.com/@wilcoln/how-to-install-hadoop-on-a-real-cluster-fully-distributed-mode-7c3bc3fa7d7e), установите и настройте ``DataNode`` на узле кластера ``node2``. Версия ``hadoop`` ``hadoop-3.3.1``.
2. Предварительно настроены ``/etc/hosts`` и установлена ``JAVA 1.8``.
3. Необходимо скачать дистрибутив, распаковать его и правильно настроить переменные окружения и файлы ``core-site.xml``, ``hdfs-site.xml`` и т.д.
4. Подключитесь к ``NameNode`` с помощью ssh и выполните команду ``hdfs dfsadmin -report`` в отчёте вы должны увидеть число узлов (Live datanodes) и свой свежедобавленный узел.
5. Перейдите на узел ``node2`` и пролистайте содержимое корневого каталога, если это удалось перейдите к заданию 2.
## Задание 2
>Работа с HDFS с помощью консольных утилит
1. Разделитесь на команды и с помощью утилиты ``hadoop`` создайте в кластере:  
1.1 Папку с идентификатором своей команды  
1.2 Внутрь папки положите файл с фамилиями участников команды  





