# Лабораторная работа №2
> Цель работы: знакомство с распределённой файловой системой HDFS.

## Задание 0
> Задача подготовить полигон

1. Установить и настроить кластер ``HDFS`` согласно инструкции [Cluster](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html) и [примеру](https://medium.com/@wilcoln/how-to-install-hadoop-on-a-real-cluster-fully-distributed-mode-7c3bc3fa7d7e)
2. Воспроизвести схему кластера из презентации (Лабораторная №2)
3. Настроить ``NameNode`` и один ``DataNode``  

## Задание 1
> Задача познакомиться с процессом добавления новых узлов в существующий кластер

1. Воспользовавшись знаниями из Задания 0 и схемой кластера из презентации (Лабораторная №2) , установите и настройте ``DataNode`` на узле кластера ``node2``. Версия ``hadoop`` ``hadoop-3.3.1``.
2. Необходимо скачать дистрибутив, распаковать его и правильно настроить переменные окружения и файлы ``core-site.xml``, ``hdfs-site.xml`` и т.д.
3. Подключитесь к ``NameNode`` с помощью ssh и выполните команду ``hdfs dfsadmin -report`` в отчёте вы должны увидеть число узлов (Live datanodes) и свой свежедобавленный узел.
4. Перейдите на узел ``node2`` и пролистайте содержимое корневого каталога, если это удалось перейдите к заданию 2.

## Задание 2
> Работа с HDFS с помощью консольных утилит

1. Разделитесь на команды и с помощью утилиты ``hadoop`` создайте в кластере:  
1.1 Папку с идентификатором своей команды  
1.2 Внутрь папки положите файл с фамилиями участников команды  





